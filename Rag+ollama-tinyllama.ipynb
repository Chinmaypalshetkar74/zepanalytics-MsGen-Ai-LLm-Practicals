{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cea13bd-3b17-4b23-8564-571270a80830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4008bcf-32b8-4495-a636-cc62d6265882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weare\\AppData\\Local\\Temp\\ipykernel_25556\\775502121.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model='tinyllama')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "llm = Ollama(model='tinyllama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d28197-15f7-4237-bffc-cf7ec2992439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India got Independence on August 15, 1947, from British colonial rule.\n"
     ]
    }
   ],
   "source": [
    "# Generate answers to a question\n",
    "question = \"When did India get Independence?\"\n",
    "response = llm.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b38d24c0-4522-488e-a303-2934fb16e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sachin Tendulkar is the founder and CEO of Mobify, an artificial intelligence (AI) technology company headquartered in Pune, India. He has been a tech entrepreneur since 2014 and has developed several successful startups in the areas of e-commerce, finance, and customer service.\n",
      "\n",
      "Tendulkar has a Bachelor's degree in Computer Science from Pune University, an MBA in Marketing & Strategy from IIM Bangalore, and has completed an Executive Program in Entrepreneurship at the Harvard Business School. He is also a regular speaker and mentor on startup founding, investment, and growth.\n",
      "\n",
      "Tendukkar's expertise lies in developing AI-driven products and services to enhance customer experience and increase efficiency in business operations. Mobify has successfully leveraged machine learning and natural language processing (NLP) technologies to develop innovative solutions for clients like Walmart, Amazon, and Alibaba. He is also a published author of several books on entrepreneurship and startup success.\n"
     ]
    }
   ],
   "source": [
    "# Generate answers to a question\n",
    "question = \"Who is Sachin Tendulkar\"\n",
    "response = llm.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b0485f-58c8-4eaf-a387-f4fb29e2c057",
   "metadata": {},
   "source": [
    "## Implementing RAG for custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d3e2fe8-4058-45b8-99b1-797599ac5f63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.document_loaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Text splitter\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.document_loaders'"
     ]
    }
   ],
   "source": [
    "# LLM (later, can use Ollama or HuggingFace)\n",
    "# import openai  # only if you use OpenAI API\n",
    "\n",
    "# Vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Embeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings import OpenAIEmbeddings  # optional\n",
    "\n",
    "# PDF loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Text splitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f69e2d-1664-4d0d-8f1e-07271b6f9e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\weare\\ansel\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\weare\\ansel\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\weare\\ansel\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.49)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\weare\\ansel\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\weare\\ansel\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\weare\\ansel\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\weare\\ansel\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain langchain-text-splitters langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fba59d02-0318-4318-aa1d-e07fe4ed895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a6a3052-586c-405a-9d13-bd943ac21bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 52\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Łukasz \n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_loader = PyPDFLoader(\"Attention Is All You Need.pdf\")\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Total Chunks:\", len(chunks))\n",
    "print(chunks[0].page_content[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "586e3e65-5dbc-4c9c-bea8-9a57a00f2c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weare\\AppData\\Local\\Temp\\ipykernel_25556\\3079478810.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Build FAISS vector store\n",
    "db = FAISS.from_documents(documents=chunks, embedding=embeddings)\n",
    "\n",
    "# Create retriever\n",
    "retriever = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08e5ea82-6839-4341-9295-0297314a958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"tinyllama\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ce625e3-1fac-4824-b68f-551d622b655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Use the following context to answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22ec8ee0-185f-429f-9b58-5d9ab44a225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The self-attention mechanism in encoder layers of pre-trained language models (e.g., BERT or GPT) involves a recurrent layer that applies a sequence of attention weights to each input token, attended by a set of previously computed keys and values based on the positions of other tokens in the sequence. This process is repeated for multiple layers until the input sequence is fully processed. The output of the self-attention mechanism is a weighted sum of the attended representations, allowing the model to generate contextualized embeddings for each token.\n",
      "\n",
      "The self-attention mechanism can be seen as a form of \"attentional embedding\" in which attention weights are applied to each input token to selectively attend to its relevant context. This can improve the representation of each token by enhancing its \"topicality\", making it easier for the model to process and understand different parts of the sequence. By allowing the self-attention mechanism to attend to the entire sequence, the model can generate more accurate representations that capture not just the individual tokens but also their relationships with each other in a hierarchical structure.\n",
      "\n",
      "The computational complexity of self-attention depends on the number of layers and width of recurrent or convolutional layers used in the encoder. However, recent work has shown that self-attention can be parallelized to improve performance by reducing the computational requirements per layer. This has been achieved by using different forms of self-attention or applying techniques such as batch normalization or dropout, which can reduce computation and speed up training.\n",
      "\n",
      "In summary, the self-attention mechanism in encoder layers of pre-trained language models can be seen as a form of \"attentional embedding\" that enhances contextualized representations of each token by attending to its relevant context. This can improve representation generation and understanding of the sequence, making the model better able to process and understand complex text or other types of data.\n"
     ]
    }
   ],
   "source": [
    "# Fetch relevant docs directly from FAISS\n",
    "docs = db.similarity_search(query, k=5)  # k = number of top relevant chunks\n",
    "\n",
    "\n",
    "# Format the context\n",
    "context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# Prepare prompt\n",
    "final_prompt = prompt.format(context=context, question=query)\n",
    "\n",
    "# Query LLM\n",
    "response = llm.invoke(final_prompt)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80273012-4609-46ab-8240-021296c0e09a",
   "metadata": {},
   "source": [
    "## Updated ask_question function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cadf965-caa6-414e-a4b5-02c1dc6c72da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-attention is a type of attention mechanism found in various layers of deep neural networks (DNNs), which maps one variable-length sequence of symbol representations (such as an input word or sentence) to another variable-length sequence of equal length (called the \"query\", \"key\", and \"value\" vectors). Self-attention is designed to compute the attention score for each possible combination of query, key, and value vectors based on the distribution of the underlying variable-length sequence.\n",
      "\n",
      "The self-attention mechanism can be understood as a way to leverage information across multiple time steps in a sequence by taking into account all possible positions where the values might occur. This is achieved by mapping each time step in the sequence to a set of \"self-attention\" operations, where each operation takes an output vector from the previous time step and a query and key vector for that time step and computes the attention score between them.\n",
      "\n",
      "The total computational complexity of self-attention is measured as the number of sequential operations required per layer. Compared to other layers such as recurrent or convolutional layers, self-attention has lower computational complexity because it only requires a single forward pass through the sequence and can be parallelized by using multiple threads or processors in modern systems.\n",
      "\n",
      "One desiderata for self-attention is its ability to perform tasks like perplexity estimation, which measures the quality of a given text representation (i.e., a set of words or sentences), without relying on pre-computed values or prior knowledge about the problem being solved. This makes self-attention ideal for applications such as language translation and machine translation, where it can extract meaningful patterns from complex input sequences.\n",
      "\n",
      "In summary, self-attention is a type of attention mechanism designed to map one variable-length sequence of symbol representations (such as an input word or sentence) to another variable-length sequence of equal length (called the \"query\", \"key\", and \"value\" vectors). It can be understood as a way to leverage information across multiple time steps in a sequence by taking into account all possible positions where the values might occur. Self-attention has lower computational complexity than other layers and is well-suited for tasks such as perplexity estimation that require understanding patterns across complex input sequences.\n"
     ]
    }
   ],
   "source": [
    "def ask_question(query):\n",
    "    # Retrieve relevant chunks\n",
    "    docs = db.similarity_search(query, k=5)\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    \n",
    "    # Prepare prompt\n",
    "    final_prompt = prompt.format(context=context, question=query)\n",
    "    \n",
    "    # Query LLM\n",
    "    response = llm.invoke(final_prompt)\n",
    "    return response\n",
    "\n",
    "# Test\n",
    "query = \"Explain self-attention mechanism\"\n",
    "answer = ask_question(query)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c01c8-0479-4162-8505-857f324aa95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c331d-b43c-4eae-adea-16073008da94",
   "metadata": {},
   "source": [
    "### Chat history - bot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7e96a-c0ce-46f4-9588-ce33a498116a",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab10489-795c-4103-b979-41e16f777eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\weare\\ansel\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\weare\\ansel\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\weare\\ansel\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: ollama in c:\\users\\weare\\ansel\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\weare\\ansel\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\weare\\ansel\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.49)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\weare\\ansel\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\weare\\ansel\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\weare\\ansel\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\weare\\ansel\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\weare\\ansel\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\weare\\ansel\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from sentence-transformers) (2.7.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\weare\\ansel\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\weare\\ansel\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\weare\\ansel\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\weare\\ansel\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\weare\\ansel\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\weare\\ansel\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\weare\\ansel\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\weare\\ansel\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\weare\\ansel\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\weare\\ansel\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (68.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\weare\\ansel\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\weare\\ansel\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\weare\\ansel\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain langchain-community langchain-text-splitters ollama sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd281f3-9ee1-454a-88ae-c0ddd8d5fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19689dae-5351-43fd-95bd-4ad2de0cf805",
   "metadata": {},
   "source": [
    "### Load PDF and Split into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91148e9-30de-4cb8-a123-14995fc9e2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 52\n"
     ]
    }
   ],
   "source": [
    "pdf_loader = PyPDFLoader(\"Attention Is All You Need.pdf\")\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Total chunks:\", len(chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ca518-6cfe-462c-aa31-299af28be8f6",
   "metadata": {},
   "source": [
    "### Create Embeddings and FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e802fd3-4147-4eac-ae3c-856394696516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weare\\AppData\\Local\\Temp\\ipykernel_15984\\3635374491.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "db = FAISS.from_documents(documents=chunks, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddebd8-084c-42e1-98ee-bdb209d22384",
   "metadata": {},
   "source": [
    "## Initialize Ollama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f49a8c-ed7c-4388-9f23-aca0e1de4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"tinyllama\",gpu=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78f0ad-dd16-4a02-bfd8-33474704485c",
   "metadata": {},
   "source": [
    "### Define PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438c086d-38d1-4ca2-8e25-47e17681c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "The following is a conversation history between a user and an AI assistant:\n",
    "{chat_history}\n",
    "\n",
    "Use the context below to answer the latest question.\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c271de-0514-45e5-bfdd-2d508179b4ca",
   "metadata": {},
   "source": [
    "### Chat History Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48ee56e-a27d-4080-9b01-3b6b32ea1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []  # list of strings: \"User: ...\\nAI: ...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d89cd-5017-49a8-85a5-2adf91af7b00",
   "metadata": {},
   "source": [
    "### Helper to combine documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15e9695-6443-455c-9563-f09c57f02f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d88410-fdd0-4667-8663-308f5c9a4fe1",
   "metadata": {},
   "source": [
    "### Ask Question Function with Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461c7686-6a61-4963-9962-34f9b21610c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(query):\n",
    "    # Retrieve relevant chunks\n",
    "    docs = db.similarity_search(query, k=5)\n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    # Combine chat history\n",
    "    history_text = \"\\n\".join(chat_history)\n",
    "    \n",
    "    # Format prompt\n",
    "    final_prompt = prompt.format(chat_history=history_text, context=context, question=query)\n",
    "    \n",
    "    # Query LLM\n",
    "    response = llm.invoke(final_prompt)\n",
    "    \n",
    "    # Update chat history\n",
    "    chat_history.append(f\"User: {query}\")\n",
    "    chat_history.append(f\"AI: {response}\")\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f1d5c-23b7-40f8-90f8-6e68a147312f",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e4121d-0ad4-4aff-9546-931b0f7816de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The self-attenition mechanism involves mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of these vectors, and the resulting vector produces an attention mechanism in which the importance or \"weight\" of each vector in the output is proportional to its contribution towards the overall goal of mapping the query to the desired output.\n",
      "\n",
      "To explain this more specifically, let us consider the case where we have a sequence of symbols (x1, ..., xn) that we want to map to a sequence of symbols (y1, ..., ym), each representing a word or a concept. We can think of the query as a single symbol that represents the desired output, and the vector representation of this query is a fixed-length vector of size n with all its elements set to 1.\n",
      "\n",
      "The weights for each of these vectors in the output are determined by the context surrounding the query. Specifically, they depend on the history of symbols that precede or follow the current symbol in the sequence (this contextual information is stored as hidden units within the recurrent layer). The weights for these vectors are learned during training to align with the weighted sum of all the input vectors in the output.\n",
      "\n",
      "This self-attention mechanism can be seen as a way of performing elementwise multiplication between each vector and its corresponding weight vector, which results in an output that represents the importance or \"weight\" of each vector in terms of the overall goal of mapping the query to the desired output. This attention mechanism allows us to compute the weights for each input vector in a more efficient and computationally-efficient way than directly computing all the weighted sums of all inputs, as we did before.\n",
      "\n",
      "In summary, self-attention is an algorithmic way of performing elementwise multiplication between vectors that represent contextual information about symbols or words in a sequence, and the weights assigned to each vector are learned during training to align with the output vector.\n",
      "Positional Encoding is a technique used in the Transformer architecture to allow the model to attend to relative positions within a sequence. The idea is to use a frequency-based representation for each dimension of the input, which allows the model to learn to attend by varying the position of an embedding vector over time. The frequencies are chosen so that they form a geometric progression from 2π to 10000 · 2π.\n",
      "\n",
      "This technique has been used in various sequence-to-sequence models, including the Transformer architecture, and has been shown to allow the model to attend to relative positions within a sequence. It helps to explain why the model can achieve good results in a wide range of tasks where attention is a common mechanism for understanding and generating information from sequences, such as language modeling, neural machine translation, and question answering.\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Explain self-attention mechanism\"\n",
    "answer1 = ask_question(query1)\n",
    "print(answer1)\n",
    "\n",
    "query2 = \"How does positional encoding work?\"\n",
    "answer2 = ask_question(query2)\n",
    "print(answer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d855a3a-92aa-46e8-b72f-035f41b2f8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
